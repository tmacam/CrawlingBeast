\documentclass[compress]{beamer}
%\mode<beamer>

% $Id$

\usepackage[utf8]{inputenc}
\usepackage[brazil]{babel}
\usepackage{graphicx}

\usetheme{Zurich}
\usepackage{tangocolors}
\usecolortheme{orchid}


% Informações sobre o documento
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\title[Language Modeling Approach]{A Language Modeling Approach to
information Retrieval}
\subtitle{Jay M. Ponte and W. Bruce Croft}
\author[Tiago Macambira]{Tiago Alves Macambira }
\institute{e-Speed \\ Departamento de Ciência da Computação \\ Universidade Federal de Minas Gerais}
\date{
Apresentação para a Disciplina de RI - 2007.1 \\
27 de junho de 2007}
\subject{Apresentação para a disciplina de Recuperação de Informação}
\logo{\includegraphics[scale=0.25]{speed}}


\begin{document}

\frame{ \titlepage }

\frame{ \frametitle{Roteiro} \tableofcontents}


\section{Introdução}
\subsection{Sobre o que se trata esse artigo}

    \begin{frame}{Sobre o que se trata esse artigo}
    \framesubtitle{20 minutos em 10 segundos}
	\begin{block}{Resumo}
            Modelo único de indexação e de recuperação utilizando modelagem probabilística
            de linguagem.
	\end{block}
    \end{frame}

\subsection{Modelos}

    \begin{frame}{Conceitos Iniciais}
    \framesubtitle{O que chamamos de modelo nesse trabalho}
            \begin{itemize}
                \item De indexação
                \begin{itemize}
                    \item Lida com o problema de determinar \emph{indexing terms} a documentos
                    \item Modelo 2-Poisson
                \end{itemize}

                \item De recuperação
                \begin{itemize}
                    \item Lida com formas de estimar a probabilidade da relevância de documentos
                    dado uma consulta do usuário
                    \item Modelo de espaço vetorial
                \end{itemize}

                \item Modelos de linguagem
                \begin{itemize}
                    \item Usados, por exemplo, em sistemas de reconhecimento de fala, OCRs etc.
                \end{itemize}
            \end{itemize}
    \end{frame}



\subsection{Motivação}

    \begin{frame}{Motivação}
            Problemas das Abordagens Tradicionais:
            \begin{itemize}
            \item Separação entre os modelos de indexação e os modelos de recuperação
            \item Suposições comumente usadas no modelo de indexação causam problemas:
                \begin{itemize}
                    \item Parametrização do modelo dos dados
                    \item Suposição de que documentos pertencem a classes pré-definidas e bem
                    definidas.
                \end{itemize}
            \item Estatísticas da coleção e dos documentos são utilizados de maneira
            \emph{ad-hoc} (heurísticas).
            \end{itemize}
    \end{frame}

\subsection{Proposta}

    \begin{frame}{Proposta}
            \begin{itemize}
            \item Estimar modelos de linguagem (LM) para cada documento individualmente

            \begin{itemize}
            \item Para que parametrizar quando você tem os dados!
            \end{itemize}
            \item Documentos são \emph{rankeados} de acordo com a probabilidade do modelo estimado
            gerar a consulta
            \end{itemize}
            \[
            \hat{p}(Q|M_{d})\]
    \end{frame}



\section{O modelo proposto}

\subsection{Definições iniciais}

    \begin{frame}{Definições iniciais}
            \begin{itemize}
            \item A distribuição de probabilidade do termo $t$ no documento $d$ é:
            \end{itemize}
            \[
            \hat{p}_{ml}(t|M_{d})=\frac{tf_{(t,d)}}{dl_{d}}\]


            \begin{itemize}
            \item Assume-se independência dos termos
            \end{itemize}
    \end{frame}

\subsection{Definindo a função de ranking}

    \begin{frame}{A função de \emph{ranking}}
    \framesubtitle{Primeira proposta}
            A função de \emph{ranking} ficaria assim:
            \[
            \prod_{t\in Q}\hat{p}_{ml}(t,d)\]
    \end{frame}



    \begin{frame}{Melhorando a função de \emph{ranking}}
            Problema:

            \begin{itemize}
                \item Se um documento não possuir um dos termos da consulta então a sua
            probabilidade será 0!!!
            \end{itemize}

            Solução: 

            \begin{itemize}
                \item termos que não ocorrem serão tão prováveis no documento como são em
            média na coleção.
            \end{itemize}
            \[
            \frac{cf_{t}}{cs}\]
    \end{frame}


    \begin{frame}{Melhorando a função de \emph{ranking}}
            Problema:

            \begin{itemize}
                \item Para estimar o ML de um dado documento, só podemos tirar estimativas
            dos dados do próprio documento!
            \end{itemize}

            Solução:

            \begin{itemize}
                \item Estimar de bases dados maiores!
                \item Obter a probabilidade média de $t$ nos documentos que o contêm.
            \end{itemize}
            \[
            p_{avg}=\frac{\left(\sum_{d_{(t\in d)}}p_{ml}(t|M_{d})\right)}{df_{t}}\]

    \end{frame}

    \begin{frame}{Melhorando a função de \emph{ranking}}

            Solução anterior ainda possui problemas:

            \begin{itemize}
                \item Nem todo documento que contêm $t$ segue o mesmo modelo
                \item Existe um risco em se usar a média para estimar $p(t|M_{d})$
            \end{itemize}

            Solução:

            \begin{itemize}
                \item Modelar o risco
            \end{itemize}
    \end{frame}

\subsection{Fórmula final}

    \begin{frame}{Melhorando a função de \emph{ranking}}
            Seja:

            \[
            \hat{p}(t|M_{d})=\begin{array}{cc}
            p_{ml}\left(t,d\right)^{(1.0-\hat{R}_{t,d})}\cdot p_{avg}\left(t\right)^{\hat{R}_{t,d}} & \quad if\; tf_{\left(t,d\right)}>0\\
            \frac{cf_{t}}{cs} & otherwise\end{array}\]


            Então

            \[
            p\left(Q|M_{d}\right)=\prod_{t\in Q}\hat{p}\left(t|M_{d}\right)\times\prod_{t\notin Q}1-\hat{p}\left(t|M_{d}\right)\]


            Ou seja, o produto entre a probabilidade de se produzir termos da
            consulta e a probabilidade de não se produzir outros termos.

    \end{frame}

\section{Experimentos e Resultados}


    \begin{frame}{Experimentos e Resultados}
            \begin{itemize}
            	\item Protótipo implementado e comparado com um modelo
                \emph{tf-idf} tradicional.
                \item Testes com a TREC (discos 2 e 4), conjuntos de
                consultas 202-205 e 51-100
                \item Houveram melhorias para todos os 11 pontos de
                precisão.
                \item Em vários casos os resultados possuem
                significância  estatística.
            \end{itemize}
    \end{frame}


    \begin{frame}{Experimentos e Resultados}
                \pgfdeclareimage[width=\textwidth]{tabela}{result1}
                \pgfuseimage{tabela}
    \end{frame}


\section{Conclusões}


\subsection{Pontos Fortes}

    \begin{frame}{Pontos Fortes}
            \begin{itemize}
                \item Argumentação e modelo coerente
                \item Ganhos em relação ao modelo de referência (vetorial)
                \item Mostrar que outras abordagens para o problema de recuperação de documentos
                são possíveis e viáveis
            \end{itemize}
    \end{frame}

\subsection{Pontos Fracos}

    \begin{frame}{Pontos Fortes}
            \begin{itemize}
                \item Muito denso - mais do que o necessário
                \item Nenhum questionamento sobre a complexidade computacional do modelo
            \end{itemize}
    \end{frame}



\section{Perguntas}
\begin{frame}{Perguntas?}
\framesubtitle{Uma pausa para seu momento de epifania\ldots}

    Dúvidas?
    \vspace{1cm}
    \pause

    Sugestões?
    \vspace{1cm}
    \pause

    \begin{block}{Contato}
    \texttt{tmacam@dcc.ufmg.br}
    \end{block}

\end{frame}

\end{document}

% vim:tw=72 syn=tex fileencoding=utf8 spelllang=pt spell autoindent:
% vim:softtabstop=4 smarttab expandtab shiftwidth=4:
